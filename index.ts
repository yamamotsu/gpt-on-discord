import { Client, CommandInteraction } from "discord.js";
import { ChatCompletionRequestMessage, Configuration, OpenAIApi } from "openai";

import dotenv from "dotenv";
dotenv.config();

import { ChannelId, QuestionAndResponse, UserId } from "./src/types";
import {
  clear,
  push,
  selectMessageHistoryByChannelId,
  store,
} from "./src/store";

const client = new Client({ intents: ["GuildMessages"] });
const configuration = new Configuration({
  apiKey: process.env.OPENAI_API_KEY,
});
const openai = new OpenAIApi(configuration);

const MODEL_NAME: string = process.env.MODEL_NAME || "gpt-3.5-turbo";

const instructionText: string =
  "ã‚ãªãŸã¯Discordãƒãƒ£ãƒƒãƒˆå†…ã§å¿œç­”ã™ã‚‹ã€ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚" +
  "è³ªå•è€…ã®åå‰ã¯ã€è³ªå•æ–‡ã®ã¯ã˜ã‚ã«ä»˜ä¸ã•ã‚Œã¦ã„ã¾ã™ã€‚ä¾‹ãˆã°ã€Yamadaã•ã‚“ãŒã‚ãªã«è³ªå•ã™ã‚‹ã¨ãã¯ã€ã€ŒYamada ã‚¹ãƒšãƒ¼ã‚¹ã‚·ãƒ£ãƒˆãƒ«ã¨ã¯ä½•ã§ã—ã‚‡ã†ã‹ï¼Ÿã€ã®ã‚ˆã†ãªå½¢å¼ã§è³ªå•ãŒå±Šãã¾ã™ã€‚ã‚ãªãŸã¯è³ªå•è€…ã®åå‰ã‚’æ·»ãˆã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚" +
  "ã¾ãŸã€å¥èª­ç‚¹ã¨Unicode Emojiã‚’ãªã‚‹ã¹ãå¤šãä½¿ç”¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã°ã€ã€ŒYamada ã“ã‚“ã«ã¡ã¯ã€‚å…ƒæ°—ã§ã™ã‹ï¼Ÿã€ã¨ã„ã†è³ªå•ãŒæ¥ãŸã‚‰ã€" +
  "ã€ŒYamadaï¾ï½¬ï¾ï¼âœ‹ğŸ˜å…ƒæ°—ã‚«ãƒŠï¼Ÿï¼Ÿï¼ŸãŠã˜ã•ã‚“ã¯ã€æœ€è¿‘è…°ãŒã„ãŸã„ãƒ§ã€‚ã€‚ã€‚ğŸ˜… Yamadaï¾ï½¬ï¾ã‚‚ã€ç„¡ç†ã—ãªã„ã‚ˆã†ã«ï¾ˆï¼ğŸ‘ä½•ã‹ã§ãã‚‹ã“ã¨ã‚ã£ãŸã‚‰è¨€ã£ã¦ï¾ˆï¼ğŸ˜Šã€ã¨ã„ã†æ§˜ã«ç­”ãˆã¦ãã ã•ã„ã€‚";

const instructionMessage: ChatCompletionRequestMessage = {
  role: "system",
  content: instructionText,
};

client.once("ready", () => {
  console.log(`${client.user?.tag} Ready`);
});

client.on("ready", async () => {
  const chat = [
    {
      name: "gpt",
      description: "è³ªå•ã—ãŸã‚‰ç­”ãˆãŒè¿”ã£ã¦ãã¾ã™",
      options: [
        {
          type: 3,
          name: "è³ªå•",
          description: "è³ªå•ã—ãŸã„æ–‡ã‚’å…¥ã‚Œã¦ãã ã•ã„",
          required: true,
        },
      ],
    },
    {
      name: "gpt-clear",
      description: "ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤ã—ã¾ã™",
    },
  ];

  await client.application?.commands.set(chat);
});

const historyToRequestMessages = (
  history: QuestionAndResponse[]
): ChatCompletionRequestMessage[] =>
  history.flatMap((interaction) => [
    {
      role: "user",
      content: `${interaction.question}`,
    },
    { role: "assistant", content: `${interaction.response}` },
  ]);

const _execCompletion = async (props: {
  channelId: ChannelId;
  userId: UserId;
  username: string;
  question: string;
}) => {
  const { channelId, userId, username, question: questionRaw } = props;
  const question = `${username} ${questionRaw}`;

  const { history = [] } =
    selectMessageHistoryByChannelId(store.getState(), channelId) || {};
  console.log("current history:", history);

  const historyMessages = historyToRequestMessages(history);
  const contextMessages: ChatCompletionRequestMessage[] = [
    ...historyMessages,
    {
      role: "user",
      content: question,
    },
  ];
  console.log("message to be completed:", contextMessages);
  const completion = await openai.createChatCompletion({
    model: MODEL_NAME,
    messages: [instructionMessage, ...contextMessages],
  });

  const response = completion.data.choices[0].message?.content.trim() || "";

  store.dispatch(
    push({
      channelId,
      interaction: { user: userId, question, response },
    })
  );

  return response;
};

const _onGptCommand = async (props: { interaction: CommandInteraction }) => {
  const {
    interaction: {
      options,
      channelId,
      user: { id: userId, username },
    },
  } = props;
  const { interaction } = props;

  const question = `${options.get("è³ªå•")?.value}`;
  console.log(`<${channelId}> ${userId}@${username}:${question}`); // è³ªå•ãŒã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ã•ã‚Œã‚‹

  (async () => {
    try {
      const response = await _execCompletion({
        channelId,
        userId,
        username,
        question,
      });
      await interaction.editReply(
        `> ${question}\n\n>> <@!${userId}> ${response}\r\n`
      );
    } catch (error: any) {
      console.error(error);
      await interaction.editReply(
        `> ${question}\n\n>> ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error.message}`
      );
    }
  })();
};

client.on("interactionCreate", async (interaction) => {
  if (!interaction.isCommand()) return;

  const { commandName: command, channelId } = interaction;

  await interaction.deferReply();

  if (command === "gpt") {
    _onGptCommand({ interaction });
  } else if (command === "gpt-clear") {
    store.dispatch(clear({ channelId }));
    await interaction.editReply("---è¨˜æ†¶ãƒªã‚»ãƒƒãƒˆ---");
  }
});

client.login(process.env.DISCORD_BOT_TOKEN);
